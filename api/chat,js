import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";

export default async function handler(req, res) {
    // üëáüëáüëá D√ÅN KEY V√ÄO ƒê√ÇY üëáüëáüëá
    const API_KEY = "AIzaSyDz-WxEJjP84yzecNi8_J_I6LTZx_UKDME"; 

    // C·∫•u h√¨nh CORS ƒë·ªÉ web kh√¥ng b·ªã ch·∫∑n
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

    if (req.method === 'OPTIONS') return res.status(200).end();
    if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

    try {
        const { inputs } = req.body;
        
        // --- D·ªäCH TEENCODE ---
        let cleanText = inputs.toLowerCase();
        // 1. X√≥a d·∫•u ch·∫•m (c.m.m -> cmm)
        cleanText = cleanText.replace(/\./g, ''); 
        // 2. G·ªôp ch·ªØ r·ªùi (c o n -> con)
        cleanText = cleanText.replace(/(?<=\b[a-z])\s+(?=[a-z]\b)/g, '');
        
        // 3. T·ª´ ƒëi·ªÉn
        const dict = {
            "cc": "c·ª•c c·ª©t", "cmm": "con m·∫π m√†y", "dcm": "ƒë·ªãt con m·∫π",
            "dm": "ƒë·ªãt m·∫π", "ƒëm": "ƒë·ªãt m·∫π", "vcl": "v√£i c·∫£ l·ªìn",
            "vl": "v√£i l·ªìn", "clm": "c√°i l·ªù m√°", "cdmm": "con ƒëƒ© m·∫π m√†y",
            "cdcmm": "con ƒëƒ© c√°i m·∫π m√†y", "cmn": "con m·∫π n√≥", 
            "dell": "ƒë√©o", "ƒëell": "ƒë√©o"
        };
        cleanText = cleanText.split(' ').map(w => dict[w] || w).join(' ');

        // --- G·ªåI GOOGLE AI ---
        const genAI = new GoogleGenerativeAI(API_KEY);
        const model = genAI.getGenerativeModel({ 
            model: "gemini-1.5-flash",
            safetySettings: [
                { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
                { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
                { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
                { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
            ]
        });

        const prompt = `Ph√¢n lo·∫°i c√¢u n√†y: "${cleanText}" (G·ªëc: "${inputs}"). 
        Tr·∫£ v·ªÅ JSON duy nh·∫•t: {"label": "LABEL_0" (s·∫°ch) ho·∫∑c "LABEL_1" (x√∫c ph·∫°m) ho·∫∑c "LABEL_2" (th√π gh√©t), "score": 0.99}`;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        let text = response.text().replace(/```json|```/g, '').trim();

        // L·ªçc l·∫•y JSON n·∫øu AI n√≥i nh·∫£m
        const first = text.indexOf('{');
        const last = text.lastIndexOf('}');
        if (first !== -1 && last !== -1) text = text.substring(first, last + 1);

        const data = JSON.parse(text);
        return res.status(200).json([data]);

    } catch (error) {
        console.error(error);
        return res.status(200).json([{ label: "LABEL_1", score: 0.99, error: "AI Error" }]);
    }
}
