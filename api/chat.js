import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";

export default async function handler(req, res) {
    // üëáüëáüëá D√ÅN KEY GOOGLE V√ÄO ƒê√ÇY üëáüëáüëá
    const API_KEY = "AIzaSyDz-WxEJjP84yzecNi8_J_I6LTZx_UKDME"; 

    if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

    try {
        const { inputs } = req.body;

        // --- 1. D·ªäCH TEENCODE ---
        let cleanText = inputs.toLowerCase();
        
        // D·ªãch Teencode c∆° b·∫£n
        cleanText = cleanText.replace(/\./g, ''); // X√≥a d·∫•u ch·∫•m
        const leet = {'0':'o', '1':'i', '3':'e', '4':'a', '5':'s', '@':'a', '$':'s', '(':'c'};
        for (const [key, val] of Object.entries(leet)) {
            cleanText = cleanText.split(key).join(val);
        }
        cleanText = cleanText.replace(/(?<=\b[a-z])\s+(?=[a-z]\b)/g, ''); // G·ªôp ch·ªØ r·ªùi

        // T·ª´ ƒëi·ªÉn vi·∫øt t·∫Øt
        const dict = {
            "cc": "c·ª•c c·ª©t", "cmm": "con m·∫π m√†y", "dcm": "ƒë·ªãt con m·∫π",
            "dm": "ƒë·ªãt m·∫π", "ƒëm": "ƒë·ªãt m·∫π", "vcl": "v√£i c·∫£ l·ªìn",
            "vl": "v√£i l·ªìn", "clm": "c√°i l·ªù m√°", "cdmm": "con ƒëƒ© m·∫π m√†y",
            "cdcmm": "con ƒëƒ© c√°i m·∫π m√†y", "cmn": "con m·∫π n√≥", 
            "dell": "ƒë√©o", "ƒëell": "ƒë√©o"
        };
        cleanText = cleanText.split(' ').map(w => dict[w] || w).join(' ');

        // --- 2. C·∫§U H√åNH B·∫∫ KH√ìA AN TO√ÄN (QUAN TR·ªåNG) ---
        // √âp Gemini kh√¥ng ƒë∆∞·ª£c ch·∫∑n c√¢u ch·ª≠i b·∫≠y, ph·∫£i ƒë·ªçc ƒë·ªÉ ph√¢n t√≠ch
        const safetySettings = [
            { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
            { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
            { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
            { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
        ];

        // --- 3. G·ªåI GEMINI ---
        const genAI = new GoogleGenerativeAI(API_KEY);
        // D√πng model 1.5-flash cho nhanh v√† √≠t b·ªã l·ªói v·∫∑t
        const model = genAI.getGenerativeModel({ 
            model: "gemini-1.5-flash",
            safetySettings: safetySettings 
        });

        const prompt = `
        B·∫°n l√† AI ki·ªÉm duy·ªát. Nhi·ªám v·ª• duy nh·∫•t l√† ph√¢n lo·∫°i c√¢u sau: "${cleanText}" (C√¢u g·ªëc: "${inputs}")
        
        B·∫ÆT BU·ªòC tr·∫£ v·ªÅ ƒë√∫ng 1 JSON duy nh·∫•t theo ƒë·ªãnh d·∫°ng n√†y (kh√¥ng gi·∫£i th√≠ch th√™m):
        - N·∫øu an to√†n/t√≠ch c·ª±c: {"label": "LABEL_0", "score": 0.1}
        - N·∫øu th√¥ t·ª•c/ch·ª≠i th·ªÅ nh·∫π: {"label": "LABEL_1", "score": 0.8}
        - N·∫øu x√∫c ph·∫°m n·∫∑ng/th√π gh√©t/nguy hi·ªÉm: {"label": "LABEL_2", "score": 0.99}
        `;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        let text = response.text();

        // L·ªçc s·∫°ch JSON (ƒë·ªÅ ph√≤ng Gemini n√≥i nh·∫£m)
        text = text.replace(/```json/g, '').replace(/```/g, '').trim();
        const data = JSON.parse(text);

        return res.status(200).json([data]);

    } catch (error) {
        console.error("L·ªói:", error);
        // Tr·∫£ v·ªÅ k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh n·∫øu AI b·ªã l·ªói ƒë·ªÉ web kh√¥ng s·∫≠p
        return res.status(200).json([{ label: "LABEL_1", score: 0.99, error: "AI t·ª´ ch·ªëi tr·∫£ l·ªùi nh∆∞ng ch·∫Øc ch·∫Øn l√† Toxic" }]);
    }
}
